---
layout: default
title: "OUHCIR: Research"
---
    <style>
        .image {
            display: block;
            max-width: 100%;
            height: auto;
        }

        .xsmall {
            width: 50px; /* Adjust this value as needed */
        }

        .left {
            float: left;
            margin-right: 20px; /* Adjust this value as needed */
            margin-bottom: 20px; /* Ensures space below the image */
        }

        .clear {
            clear: both;
        }

        .new-line {
            display: block;
            margin-top: 20px; /* Adjust this value as needed */
	.limited-width {
            max-width: 600px; /* Adjust this value as needed */
            margin: 0 auto; /* Center the paragraph */
            text-align: justify;
            text-justify: inter-word;
        }
    </style>

<div class="row">
	<div class="12u(mobile) important(mobile)">
	<a name="Project"></a><h2>Trustworthy AI Technologies and Experiences (TATE)</h4>	
		<section>
			<span class="image xsmall left"><img src="images/projects/TATE.png" alt="" /></span>
			<a name="About"></a><h4>Introduction</h4>
				<p style="text-align: justify;text-justify: inter-word;" >
					In TATE research conducted in our HCIR lab, we critically examine the foundation of existing user models and human-AI systems. We are committed to developing robust AI auditing and bias mitigation techniques, and we aim to foster sustainable human-AI collaborations. Our team also creates innovative programs and materials to train the next generation of researchers and technology leaders in the field of trustworthy AI. We envision a future where everyone can safely and inspiringly interact with AI systems that align with human ethics, contributing to a fair and healthy society supported by human-centered AI.
				</p>
		</section>
		<section class="clear new-line">
		        <h4>On-Going Projects</h4>
				<ul>
					<li>
						AI Harm Measurements and Mitigation
					</li>
					<li>
						Human Vulnerability and Behavioral Manipulation of AI Systems
					</li>
					<li>
						Expectation Confirmation and Functional Fixedness in Human-AI Interaction
					</li>
					<li>
						Cognitive and Algorithmic Biases in Medical Information Retrieval and Evaluation
					</li>
					<li>
						Evaluation of Generative AI in Long-term Task Performance
					</li>
				</ul>
			<!-- <a href="all-updates.html" class="button alt">More Updates</a> -->
		</section>
	        <section class="new-line">
			<a name="Peo"></a><h4>People</h4>
			<ul>
				<li>
					<strong>Faculty:</strong> Dr. Jiqun Liu
				</li>
				<li>
					<strong>Student:</strong> Ben Wang, Jameshed Karimnazarov
				</li>
				
			</ul>
		</section>
</div>
</div>

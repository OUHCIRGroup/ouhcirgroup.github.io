<!DOCTYPE html><!--t7jZKZyvIwg4j_ZNNhE1m--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/chunks/c8634649255163c3.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/a09ab61d4fa91512.js"/><script src="/_next/static/chunks/242188bb71c223d6.js" async=""></script><script src="/_next/static/chunks/652ad0aa26265c47.js" async=""></script><script src="/_next/static/chunks/023d923a37d494fc.js" async=""></script><script src="/_next/static/chunks/turbopack-9b5c043ba494dbce.js" async=""></script><script src="/_next/static/chunks/7f27f9630a007744.js" async=""></script><script src="/_next/static/chunks/9c9a26e9a3ed5494.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/247eb132b7f7b574.js" async=""></script><script src="/_next/static/chunks/104a486d206275a0.js" async=""></script><meta name="next-size-adjust" content=""/><title>HCIR Lab</title><meta name="description" content="At the OU Human-Computer Interaction and Recommendation (HCIR) Lab, we are working toward modeling and supporting people’s problem-solving and decision-making activities with intelligent information search and recommender systems, and understanding the economic, societal, and ethical impacts of advanced search and recommendation algorithms."/><link rel="icon" href="/favicon.ico?favicon.8b2cd6cb.ico" sizes="32x18" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased flex min-h-screen flex-col bg-white"><div hidden=""><!--$--><!--/$--></div><header class=" sticky top-0 z-60 w-full border-b bg-white/90 dark:bg-black/90 backdrop-blur "><div class=" mx-auto flex max-w-6xl items-center justify-between px-4 py-3 "><a class="flex items-center gap-2" href="/"><span class="flex flex-col leading-tight"><span class="bg-linear-to-r from-blue-600 via-violet-600 to-purple-600 bg-clip-text text-3xl font-extrabold text-transparent md:pl-11">HCIR Lab</span></span></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" data-slot="navigation-menu" data-viewport="false" class="group/navigation-menu relative max-w-max flex-1 items-center justify-center ml-auto hidden md:flex"><div style="position:relative"><ul data-orientation="horizontal" data-slot="navigation-menu-list" class="group flex flex-1 list-none items-center justify-center gap-1 flex-wrap" dir="ltr"><li data-slot="navigation-menu-item" class="relative hidden md:block"><button id="radix-_R_4jb_-trigger-radix-_R_2sjb_" data-state="closed" aria-expanded="false" aria-controls="radix-_R_4jb_-content-radix-_R_2sjb_" data-slot="navigation-menu-trigger" class="group inline-flex h-9 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=open]:hover:bg-accent data-[state=open]:text-accent-foreground data-[state=open]:focus:bg-accent data-[state=open]:bg-accent/50 focus-visible:ring-ring/50 outline-none transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1 group" data-radix-collection-item="">Home<!-- --> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down relative top-[1px] ml-1 size-3 transition duration-300 group-data-[state=open]:rotate-180" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></button></li><li data-slot="navigation-menu-item" class="relative"><a data-slot="navigation-menu-link" class="data-[active=true]:focus:bg-accent data-[active=true]:hover:bg-accent data-[active=true]:bg-accent/50 data-[active=true]:text-accent-foreground [&amp;_svg:not([class*=&#x27;text-&#x27;])]:text-muted-foreground flex-col gap-1 p-2 [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 group inline-flex h-9 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=open]:hover:bg-accent data-[state=open]:text-accent-foreground data-[state=open]:focus:bg-accent data-[state=open]:bg-accent/50 focus-visible:ring-ring/50 outline-none transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1" data-radix-collection-item="" href="/people/">People</a></li><li data-slot="navigation-menu-item" class="relative hidden md:block"><button id="radix-_R_4jb_-trigger-radix-_R_6sjb_" data-state="closed" aria-expanded="false" aria-controls="radix-_R_4jb_-content-radix-_R_6sjb_" data-slot="navigation-menu-trigger" class="group inline-flex h-9 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=open]:hover:bg-accent data-[state=open]:text-accent-foreground data-[state=open]:focus:bg-accent data-[state=open]:bg-accent/50 focus-visible:ring-ring/50 outline-none transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1 group" data-radix-collection-item="">Research<!-- --> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down relative top-[1px] ml-1 size-3 transition duration-300 group-data-[state=open]:rotate-180" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></button></li><li data-slot="navigation-menu-item" class="relative"><a data-slot="navigation-menu-link" class="data-[active=true]:focus:bg-accent data-[active=true]:hover:bg-accent data-[active=true]:bg-accent/50 data-[active=true]:text-accent-foreground [&amp;_svg:not([class*=&#x27;text-&#x27;])]:text-muted-foreground flex-col gap-1 p-2 [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 group inline-flex h-9 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=open]:hover:bg-accent data-[state=open]:text-accent-foreground data-[state=open]:focus:bg-accent data-[state=open]:bg-accent/50 focus-visible:ring-ring/50 outline-none transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1" data-radix-collection-item="" href="/publications/">Publications</a></li><li data-slot="navigation-menu-item" class="relative"><a data-slot="navigation-menu-link" class="data-[active=true]:focus:bg-accent data-[active=true]:hover:bg-accent data-[active=true]:bg-accent/50 data-[active=true]:text-accent-foreground [&amp;_svg:not([class*=&#x27;text-&#x27;])]:text-muted-foreground flex-col gap-1 p-2 [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 group inline-flex h-9 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=open]:hover:bg-accent data-[state=open]:text-accent-foreground data-[state=open]:focus:bg-accent data-[state=open]:bg-accent/50 focus-visible:ring-ring/50 outline-none transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1" data-radix-collection-item="" href="/contact/">Contact Us</a></li></ul></div></nav><button type="button" class=" inline-flex items-center justify-center rounded-md border border-zinc-200 bg-white px-2.5 py-1.5 text-sm font-medium text-zinc-700 shadow-sm hover:bg-zinc-50 dark:border-zinc-700 dark:bg-zinc-900 dark:text-zinc-100 dark:hover:bg-zinc-800 md:hidden " aria-label="Toggle navigation menu" aria-expanded="false"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5" aria-hidden="true"><path d="M4 5h16"></path><path d="M4 12h16"></path><path d="M4 19h16"></path></svg></button></div></header><section class="sticky top-0 z-50 relative  bg-white/90 px-6 py-2 shadow-sm backdrop-blur"><div class="relative"><h2 class=" text-center bg-linear-to-r from-blue-600 via-violet-600 to-purple-600 bg-clip-text text-2xl font-extrabold tracking-tight text-transparent sm:text-3xl">Human-Computer Interaction &amp; Recommendation Lab</h2></div></section><main class="flex-1"><div class="font-sans"><main class="mx-auto flex w-full max-w-6xl flex-col px-6 py-4 sm:px-10 lg:px-16"><section id="about" class="grid w-full gap-10 scroll-mt-24 md:grid-cols-2 md:items-start"><aside class="flex justify-center md:justify-start"><img alt="OU HCIR Lab" loading="lazy" width="600" height="600" decoding="async" data-nimg="1" class="object-contain" style="color:transparent" src="/hcir.png"/></aside><section class="space-y-3 md:text-left text-justify"><p class="text-md leading-relaxed text-left text-zinc-700 dark:text-zinc-300">At the<!-- --> <span class="font-bold">OU Human-Computer Interaction and Recommendation</span> <!-- -->(HCIR) Lab, we are working toward modeling and supporting people’s problem-solving and decision-making activities with intelligent information search and recommender systems, and understanding the economic, societal, and ethical impacts of advanced search and recommendation algorithms.</p><p class="text-md leading-relaxed text-left text-zinc-700 dark:text-zinc-300">Our long-term research goal is to provide useful, timely, fair, and responsible information support for people from diverse backgrounds and communities. Our methods include computational approaches such as data/text mining, deep learning, and natural language processing, as well as qualitative, participatory, and user study research methods.</p></section><div class="md:col-span-2 md:row-start-2 space-y-3 -mt-2"><p class="text-md leading-relaxed text-left text-zinc-700 dark:text-zinc-300">Topics of interest include user biases in information interactions, intelligent information retrieval, bias-aware recommender systems, and adaptive information system evaluation.</p><p class="text-md leading-relaxed text-left text-zinc-700 dark:text-zinc-300">The Principal Investigator,<!-- --> <a class="font-bold text-blue-500" target="_blank" rel="noreferrer" href="https://jiqunl.github.io/me/">Dr. Jiqun Liu</a>, started this lab in 2020. Dr. Liu is an interdisciplinary information science researcher by training, with research interests, including information retrieval, recommender system, bounded rationality, and ethics in human-computer interaction.</p></div></section><section id="lab-news" class="mt-12 border-t border-zinc-200 pt-8 scroll-mt-24 dark:border-zinc-800"><h2 class="text-xl  font-bold tracking-tight text-blue-500">Lab News</h2><div class="mt-6 space-y-8"><div class="space-y-3"><h3 class="text-md font-semibold uppercase tracking-[0.18em] text-zinc-500 dark:text-zinc-400">2025</h3><ul class="space-y-2 text-md leading-relaxed text-zinc-700 dark:text-zinc-300"><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>PhD candidate Ben Wang has successfully defended his dissertation titled “LLM-based Long-Term Life Task Planning to Reduce Human Uncertainty”. He is now working as an Applied Scientist at Amazon. Congratulations!</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>New Grant: Institute of Museum and Library Services (IMLS) NLG award: “Gauging Library Needs for Integrating Generative AI into Children’s Maker-based Learning”. ($150,000, PI: Dr. Jiqun Liu, co-PI: Dr. Yong Ju Jung).</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>PhD student Maddy Nazari passed her General Exam. Congratulations!</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>Our paper “Re-rankers are effective reference judgment predictors” (with Chuan Meng, Jiqun Liu, Mohammad Aliannejadi, Fengran Mo, and Maarten de Rijke) accepted to LLM4EVAL workshop at ACM SIGIR 2025!</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>Our project “Syllabi and Activities for AI-Assisted Maker Education: Design and Evaluation” received a funding award of $9,964 from OU DISC Summer AI Project Seed Funding program.</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>PhD Candidate Ben Wang passed his dissertation proposal (titled “LLM-based long-term task planning to reduce human uncertainty”) defense! Congratulations!</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>We (Drs. Anett Hoppe, Ran Yu, Jiqun Liu, and Nilavra Bhattacharya) co-organized the 5th International Workshop on Investigating learning during Web search (IWILDS 2025) at WSDM (March 14, 2025).</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>Our Special issue “AI in education: transforming teaching and learning” published at Information and Learning Sciences. (Guest editors: Drs. Dania Bilal, Jiangen He, Jiqun Liu).</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>New grant: Faculty Investment Program (FIP) Award: Making mistakes like humans: Detecting biased judgments of artificial intelligence, University of Oklahoma Office of the Vice President for Research and Partnerships ($15,000, PI: Jiqun Liu).</span></li></ul></div><div class="space-y-3"><h3 class="text-md font-semibold uppercase tracking-[0.18em] text-zinc-500 dark:text-zinc-400">2024</h3><ul class="space-y-2 text-md leading-relaxed text-zinc-700 dark:text-zinc-300"><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>Award: Jamshed Karimnazarov received Undergraduate Research Opportunities Program award. Congratulations!</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>Award: The research proposal titled “Enhancing AI Literacy through Maker-based Learning with Generative AI”, co-authored by Dr. Yong Ju Jung and Dr. Jiqun Liu, has received the Elfreda A. Chatman Research Award 2024 from ASIS&amp;T SIG USE.</span></li><li class="flex gap-2"><span class="mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500"></span><span>New grant: Project titled “Functional fixedness evaluation in human-large language model (LLM) interaction” received funding support from Microsoft Research ($20,000, PI: Jiqun Liu).</span></li></ul></div></div></section><section id="join-us" class="mt-12 border-t border-zinc-200 pt-8 scroll-mt-24 dark:border-zinc-800"><h2 class="text-xl font-bold tracking-tight text-blue-500">Join Us</h2><div class="mt-4 space-y-4 text-md leading-relaxed text-zinc-700 dark:text-zinc-300"><p>We are actively looking for self-motivated students to join the lab and work on interesting cutting-edge problems in HCIR-related topics. Research opportunities are available at both undergraduate and graduate levels. We are especially interested in students with any of the following backgrounds:</p><ul class="space-y-2"><li class="list-disc pl-5">Human-Computer Interaction, Interactive Information Seeking/Retrieval, Cognitive Psychology or Experimental Economics using quantitative or qualitative methods (or both);</li><li class="list-disc pl-5">Machine Learning, Natural Language Processing (NLP), or Text/Data Mining.</li></ul><p class="text-md">If you are interested, please email<!-- --> <a href="mailto:jiqunliu@ou.edu" class="font-medium text-blue-600 underline-offset-2 hover:underline">jiq‌unliu@ou.edu</a> <!-- -->with your CV and a brief description of your previous research experiences and current research interests.</p></div></section></main></div><!--$--><!--/$--></main><footer class="mt-auto border-t border-zinc-200 bg-zinc-50 py-6 text-sm text-zinc-600 dark:border-zinc-800 dark:bg-black dark:text-zinc-400"><div class="mx-auto flex w-full max-w-6xl flex-col gap-2 px-6 sm:flex-row sm:items-center sm:justify-between sm:px-10 lg:px-16"><div><p>© <!-- -->2026<!-- --> OUHCIR Lab. All rights reserved.</p></div><div class="text-xs sm:text-sm"><p>Bizzell Library, Room 120, University of Oklahoma, 401 West Brooks, Norman, OK 73019</p></div></div></footer><script src="/_next/static/chunks/a09ab61d4fa91512.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[70119,[\"/_next/static/chunks/7f27f9630a007744.js\",\"/_next/static/chunks/9c9a26e9a3ed5494.js\"],\"Header\"]\n3:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n4:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n5:I[5500,[\"/_next/static/chunks/7f27f9630a007744.js\",\"/_next/static/chunks/9c9a26e9a3ed5494.js\",\"/_next/static/chunks/104a486d206275a0.js\"],\"Image\"]\nd:I[68027,[],\"default\"]\n:HL[\"/_next/static/chunks/c8634649255163c3.css\",\"style\"]\n:HL[\"/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"t7jZKZyvIwg4j_ZNNhE1m\",\"c\":[\"\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/c8634649255163c3.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/7f27f9630a007744.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/9c9a26e9a3ed5494.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased flex min-h-screen flex-col bg-white\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"section\",null,{\"className\":\"sticky top-0 z-50 relative  bg-white/90 px-6 py-2 shadow-sm backdrop-blur\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative\",\"children\":[\"$\",\"h2\",null,{\"className\":\" text-center bg-linear-to-r from-blue-600 via-violet-600 to-purple-600 bg-clip-text text-2xl font-extrabold tracking-tight text-transparent sm:text-3xl\",\"children\":\"Human-Computer Interaction \u0026 Recommendation Lab\"}]}]}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"mt-auto border-t border-zinc-200 bg-zinc-50 py-6 text-sm text-zinc-600 dark:border-zinc-800 dark:bg-black dark:text-zinc-400\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto flex w-full max-w-6xl flex-col gap-2 px-6 sm:flex-row sm:items-center sm:justify-between sm:px-10 lg:px-16\",\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2026,\" OUHCIR Lab. All rights reserved.\"]}]}],[\"$\",\"div\",null,{\"className\":\"text-xs sm:text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"Bizzell Library, Room 120, University of Oklahoma, 401 West Brooks, Norman, OK 73019\"}]}]]}]}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"font-sans\",\"children\":[\"$\",\"main\",null,{\"className\":\"mx-auto flex w-full max-w-6xl flex-col px-6 py-4 sm:px-10 lg:px-16\",\"children\":[[\"$\",\"section\",null,{\"id\":\"about\",\"className\":\"grid w-full gap-10 scroll-mt-24 md:grid-cols-2 md:items-start\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"flex justify-center md:justify-start\",\"children\":[\"$\",\"$L5\",null,{\"src\":\"/hcir.png\",\"alt\":\"OU HCIR Lab\",\"height\":600,\"width\":600,\"className\":\"object-contain\"}]}],[\"$\",\"section\",null,{\"className\":\"space-y-3 md:text-left text-justify\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-md leading-relaxed text-left text-zinc-700 dark:text-zinc-300\",\"children\":[\"At the\",\" \",[\"$\",\"span\",null,{\"className\":\"font-bold\",\"children\":\"OU Human-Computer Interaction and Recommendation\"}],\" \",\"(HCIR) Lab, we are working toward modeling and supporting people’s problem-solving and decision-making activities with intelligent information search and recommender systems, and understanding the economic, societal, and ethical impacts of advanced search and recommendation algorithms.\"]}],\"$L6\"]}],\"$L7\"]}],\"$L8\",\"$L9\"]}]}],[\"$La\"],\"$Lb\"]}],{},null,false,false]},null,false,false],\"$Lc\",false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[22016,[\"/_next/static/chunks/7f27f9630a007744.js\",\"/_next/static/chunks/9c9a26e9a3ed5494.js\",\"/_next/static/chunks/104a486d206275a0.js\"],\"\"]\n10:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\n11:\"$Sreact.suspense\"\n13:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\n15:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\n6:[\"$\",\"p\",null,{\"className\":\"text-md leading-relaxed text-left text-zinc-700 dark:text-zinc-300\",\"children\":\"Our long-term research goal is to provide useful, timely, fair, and responsible information support for people from diverse backgrounds and communities. Our methods include computational approaches such as data/text mining, deep learning, and natural language processing, as well as qualitative, participatory, and user study research methods.\"}]\n7:[\"$\",\"div\",null,{\"className\":\"md:col-span-2 md:row-start-2 space-y-3 -mt-2\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-md leading-relaxed text-left text-zinc-700 dark:text-zinc-300\",\"children\":\"Topics of interest include user biases in information interactions, intelligent information retrieval, bias-aware recommender systems, and adaptive information system evaluation.\"}],[\"$\",\"p\",null,{\"className\":\"text-md leading-relaxed text-left text-zinc-700 dark:text-zinc-300\",\"children\":[\"The Principal Investigator,\",\" \",[\"$\",\"$Le\",null,{\"className\":\"font-bold text-blue-500\",\"href\":\"https://jiqunl.github.io/me/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":\"Dr. Jiqun Liu\"}],\", started this lab in 2020. Dr. Liu is an interdisciplinary information science researcher by training, with research interests, including information retrieval, recommender system, bounded rationality, and ethics in human-computer interaction.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"section\",null,{\"id\":\"lab-news\",\"className\":\"mt-12 border-t border-zinc-200 pt-8 scroll-mt-24 dark:border-zinc-800\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-xl  font-bold tracking-tight text-blue-500\",\"children\":\"Lab News\"}],[\"$\",\"div\",null,{\"className\":\"mt-6 space-y-8\",\"children\":[[\"$\",\"div\",\"2025\",{\"className\":\"space-y-3\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-md font-semibold uppercase tracking-[0.18em] text-zinc-500 dark:text-zinc-400\",\"children\":2025}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-md leading-relaxed text-zinc-700 dark:text-zinc-300\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"PhD candidate Ben Wang has successfully defended his dissertation titled “LLM-based Long-Term Life Task Planning to Reduce Human Uncertainty”. He is now working as an Applied Scientist at Amazon. Congratulations!\"}]]}],[\"$\",\"li\",\"1\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"New Grant: Institute of Museum and Library Services (IMLS) NLG award: “Gauging Library Needs for Integrating Generative AI into Children’s Maker-based Learning”. ($150,000, PI: Dr. Jiqun Liu, co-PI: Dr. Yong Ju Jung).\"}]]}],[\"$\",\"li\",\"2\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"PhD student Maddy Nazari passed her General Exam. Congratulations!\"}]]}],[\"$\",\"li\",\"3\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"Our paper “Re-rankers are effective reference judgment predictors” (with Chuan Meng, Jiqun Liu, Mohammad Aliannejadi, Fengran Mo, and Maarten de Rijke) accepted to LLM4EVAL workshop at ACM SIGIR 2025!\"}]]}],[\"$\",\"li\",\"4\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"Our project “Syllabi and Activities for AI-Assisted Maker Education: Design and Evaluation” received a funding award of $9,964 from OU DISC Summer AI Project Seed Funding program.\"}]]}],[\"$\",\"li\",\"5\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"PhD Candidate Ben Wang passed his dissertation proposal (titled “LLM-based long-term task planning to reduce human uncertainty”) defense! Congratulations!\"}]]}],[\"$\",\"li\",\"6\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"We (Drs. Anett Hoppe, Ran Yu, Jiqun Liu, and Nilavra Bhattacharya) co-organized the 5th International Workshop on Investigating learning during Web search (IWILDS 2025) at WSDM (March 14, 2025).\"}]]}],[\"$\",\"li\",\"7\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"Our Special issue “AI in education: transforming teaching and learning” published at Information and Learning Sciences. (Guest editors: Drs. Dania Bilal, Jiangen He, Jiqun Liu).\"}]]}],[\"$\",\"li\",\"8\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"New grant: Faculty Investment Program (FIP) Award: Making mistakes like humans: Detecting biased judgments of artificial intelligence, University of Oklahoma Office of the Vice President for Research and Partnerships ($15,000, PI: Jiqun Liu).\"}]]}]]}]]}],\"$Lf\"]}]]}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"section\",null,{\"id\":\"join-us\",\"className\":\"mt-12 border-t border-zinc-200 pt-8 scroll-mt-24 dark:border-zinc-800\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-xl font-bold tracking-tight text-blue-500\",\"children\":\"Join Us\"}],[\"$\",\"div\",null,{\"className\":\"mt-4 space-y-4 text-md leading-relaxed text-zinc-700 dark:text-zinc-300\",\"children\":[[\"$\",\"p\",null,{\"children\":\"We are actively looking for self-motivated students to join the lab and work on interesting cutting-edge problems in HCIR-related topics. Research opportunities are available at both undergraduate and graduate levels. We are especially interested in students with any of the following backgrounds:\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-2\",\"children\":[[\"$\",\"li\",null,{\"className\":\"list-disc pl-5\",\"children\":\"Human-Computer Interaction, Interactive Information Seeking/Retrieval, Cognitive Psychology or Experimental Economics using quantitative or qualitative methods (or both);\"}],[\"$\",\"li\",null,{\"className\":\"list-disc pl-5\",\"children\":\"Machine Learning, Natural Language Processing (NLP), or Text/Data Mining.\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-md\",\"children\":[\"If you are interested, please email\",\" \",[\"$\",\"a\",null,{\"href\":\"mailto:jiqunliu@ou.edu\",\"className\":\"font-medium text-blue-600 underline-offset-2 hover:underline\",\"children\":\"jiq‌unliu@ou.edu\"}],\" \",\"with your CV and a brief description of your previous research experiences and current research interests.\"]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/104a486d206275a0.js\",\"async\":true,\"nonce\":\"$undefined\"}]\nb:[\"$\",\"$L10\",null,{\"children\":[\"$\",\"$11\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@12\"}]}]\nc:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L13\",null,{\"children\":\"$@14\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L15\",null,{\"children\":[\"$\",\"$11\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@16\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]\n"])</script><script>self.__next_f.push([1,"f:[\"$\",\"div\",\"2024\",{\"className\":\"space-y-3\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-md font-semibold uppercase tracking-[0.18em] text-zinc-500 dark:text-zinc-400\",\"children\":2024}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-md leading-relaxed text-zinc-700 dark:text-zinc-300\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"Award: Jamshed Karimnazarov received Undergraduate Research Opportunities Program award. Congratulations!\"}]]}],[\"$\",\"li\",\"1\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"Award: The research proposal titled “Enhancing AI Literacy through Maker-based Learning with Generative AI”, co-authored by Dr. Yong Ju Jung and Dr. Jiqun Liu, has received the Elfreda A. Chatman Research Award 2024 from ASIS\u0026T SIG USE.\"}]]}],[\"$\",\"li\",\"2\",{\"className\":\"flex gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mt-1.5 h-1.25 w-1.25 shrink-0 rounded-full bg-zinc-400 dark:bg-zinc-500\"}],[\"$\",\"span\",null,{\"children\":\"New grant: Project titled “Functional fixedness evaluation in human-large language model (LLM) interaction” received funding support from Microsoft Research ($20,000, PI: Jiqun Liu).\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"17:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\n16:[[\"$\",\"title\",\"0\",{\"children\":\"HCIR Lab\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"At the OU Human-Computer Interaction and Recommendation (HCIR) Lab, we are working toward modeling and supporting people’s problem-solving and decision-making activities with intelligent information search and recommender systems, and understanding the economic, societal, and ethical impacts of advanced search and recommendation algorithms.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.8b2cd6cb.ico\",\"sizes\":\"32x18\",\"type\":\"image/x-icon\"}],[\"$\",\"$L17\",\"3\",{}]]\n12:null\n"])</script></body></html>